{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "\n",
    "## The Curse of Dimensionality and Reasons for Dimensionality Reduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To practice PCA, we first retrieve the familiar 20 newsgroups documents as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Using PCA (Principal Component Analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Create a list of topics you want to select from the 20 topics\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2034\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the data\n",
    "print(f\"Number of documents: {len(newsgroups_train.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Nanci Ann Miller <nm0w+@andrew.cmu.edu>\n",
      "Subject: Re: Genocide is Caused by Atheism\n",
      "Organization: Sponsored account, School of Computer Science, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 27\n",
      "NNTP-Posting-Host: andrew.cmu.edu\n",
      "In-Reply-To: <1993Apr5.020504.19326@ultb.isc.rit.edu>\n",
      "\n",
      "snm6394@ultb.isc.rit.edu (S.N. Mozumder ) writes:\n",
      "> More horrible deaths resulted from atheism than anything else.\n",
      "\n",
      "There are definitely quite a few horrible deaths as the result of both\n",
      "atheists AND theists.  I'm sure Bobby can list quite a few for the atheist\n",
      "side but fails to recognize that the theists are equally proficient at\n",
      "genocide.  Perhaps, since I'm a bit weak on history, somone here would like\n",
      "to give a list of wars caused/led by theists?  I can think of a few (Hitler\n",
      "claimed to be a Christian for example) but a more complete list would\n",
      "probably be more effective in showing Bobby just how absurd his statement\n",
      "is.\n",
      "\n",
      "> Peace,\n",
      "\n",
      "On a side note, I notice you always sign your posts \"Peace\".  Perhaps you\n",
      "should take your own advice and leave the atheists in peace with their\n",
      "beliefs?\n",
      "\n",
      "> Bobby Mozumder\n",
      "\n",
      "Nanci\n",
      "\n",
      ".........................................................................\n",
      "If you know (and are SURE of) the author of this quote, please send me\n",
      "email (nm0w+@andrew.cmu.edu):\n",
      "Lying to ourselves is more deeply ingrained than lying to others.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the 5th document\n",
    "print(newsgroups_train.data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the category index of the 5th document\n",
    "category_index = newsgroups_train.target[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the category name using the index\n",
    "category_name = newsgroups_train.target_names[category_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: alt.atheism\n"
     ]
    }
   ],
   "source": [
    "# Print the category name\n",
    "print(f\"Category: {category_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove parts of the email that may provide hints for classification, leaving only the content for pure classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "# Remove parts that provide hints (headers, footers, quotes) to classify purely based on the content\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "# Load the test dataset\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing preprocessing steps such as tokenization, stopword removal, and stemming as done before, the data is prepared for document classification by converting it into a feature vector based on Bag of Words (BOW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/minjoo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/minjoo/minjoo/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "X_train = newsgroups_train.data   # Training dataset documents\n",
    "y_train = newsgroups_train.target # Training dataset labels\n",
    "\n",
    "X_test = newsgroups_test.data     # Test dataset documents\n",
    "y_test = newsgroups_test.target   # Test dataset labels\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # Define tokenizer using regular expressions\n",
    "english_stops = set(stopwords.words('english')) # Load English stopwords\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower()) # Check if this works as expected\n",
    "    # Exclude stopwords\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    # Apply Porter Stemmer\n",
    "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
    "    return features\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # Transform the training set\n",
    "X_test_tfidf = tfidf.transform(X_test) # Transform the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the classification performance after dimensionality reduction, the classification performance before dimensionality reduction is measured in advance using Scikit-learn's Logistic Regression library as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.962\n",
      "#Test set score: 0.761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "LR_clf = LogisticRegression()  # Declare the classifier\n",
    "LR_clf.fit(X_train_tfidf, y_train)  # Train the classifier using the train data\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scikit-learn provides the PCA library to support Principal Component Analysis.\n",
    "- Parameters:\n",
    "    -  n_components: Specifies the size of the dimensions to reduce.\n",
    "    - svd_solver: The default is auto, which automatically selects the solver considering the original and target dimensions. If you donâ€™t want to deal with this, you can leave it as the default.\n",
    "    - explained_variance: The variance explained by each new axis.\n",
    "    - explained_variance_ratio: Represents the ratio of the explained variance to the total variance before reduction. -> If the new axes explain all the original variance, the sum of explained_variance_ratio will be 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the following example, the dimensionality is reduced from 20,085 to 2,000. ('2,034' represents the number of documents. In other words, this TF-IDF matrix contains information about 2,034 documents, and 20,085 represents the number of unique words (features, tokens)).\n",
    "    - Therefore, this matrix can be viewed as a two-dimensional array structure where each document (2,034 documents) has weights (TF-IDF values) related to 20,085 unique words.\n",
    "    - These values represent how important a particular word (its weight) is in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tfidf matrix shape: (2034, 20085)\n",
      "PCA Converted matrix shape: (2034, 2000)\n",
      "Sum of explained variance ratio: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2000, random_state=7)\n",
    "# Scikit-learn's PCA does not directly support operations on sparse vector formats.\n",
    "# In other words, you cannot directly pass the matrix transformed by CountVectorizer or TfidfVectorizer as an argument.\n",
    "# Therefore, as shown below, first convert the format using the `toarray()` method, and then pass it as an argument to the `transform()` or `fit_transform()` methods.\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray()) \n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "\n",
    "print('Original tfidf matrix shape:', X_train_tfidf.shape)  # The original dimensionality can be calculated\n",
    "print('PCA Converted matrix shape:', X_train_pca.shape)\n",
    "# After reduction, the sum of 'explained_variance_ratio_' is printed to see how much of the original variance is explained.\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see from the results, the original dimensionality is 20,085, which represents the number of words in the feature vector, and the reduced dimensionality is 2,000, as intended.\n",
    "- Since the original number of dimensions is large, the computation is quite intensive, and as a result, it takes a considerable amount of time.\n",
    "- Although it took some time, the dimensionality was reduced to almost 1/10, and the explained variance is still almost 100%, meaning there is minimal information loss.\n",
    "- Let's examine the performance change by classifying the documents using the reduced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.962\n",
      "#Test set score: 0.760\n"
     ]
    }
   ],
   "source": [
    "LR_clf.fit(X_train_pca, y_train)\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the results above, we can confirm that the performance is the same as before dimensionality reduction. \n",
    "- PCA maintains the maximum amount of information through linear combinations, so it produces different performance compared to feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how does it compare with feature selection using Lasso regression? To explore this, let's first perform Lasso regression as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.790\n",
      "#Test set score: 0.718\n",
      "#Used features count: 321 out of 20085\n"
     ]
    }
   ],
   "source": [
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# {:.3f} is used in Python's string formatting to display numbers up to 3 decimal places\n",
    "print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "import numpy as np\n",
    "# Print the number of non-zero coefficients (features that were used)\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.142\n"
     ]
    }
   ],
   "source": [
    "value = 3.14159\n",
    "print('{:.3f}'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the results above, we can see that the final number of features used is 321, and the performance on the text set has significantly dropped to 0.718 compared to before dimensionality reduction.\n",
    "- For comparison with PCA, let's set the target dimension to 321, the same as in Lasso regression, and train the model with the transformed data as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Converted X shape: (2034, 321)\n",
      "Sum of explained variance ratio: 0.437\n",
      "#Train set score: 0.874\n",
      "#Test set score: 0.752\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=321, random_state=7)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "print('PCA Converted X shape:', X_train_pca.shape)\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))\n",
    "\n",
    "LR_clf.fit(X_train_pca, y_train)\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Despite the explained variance ratio dropping significantly to 43.7%, the accuracy on the text set only decreased by 1%, from 76.1% to 75.1%.\n",
    "- Therefore, although the reduced dimensionality is the same as in Lasso regression, the classifier's performance is far superior.\n",
    "- Now, let's be a little more ambitious and reduce the dimensionality to 100 as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Converted X shape: (2034, 100)\n",
      "Sum of explained variance ratio: 0.211\n",
      "#Train set score: 0.808\n",
      "#Test set score: 0.738\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=100, random_state=7)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "print('PCA Converted X shape:', X_train_pca.shape)\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))\n",
    "\n",
    "LR_clf.fit(X_train_pca, y_train)\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy on the test set is 73.8%, which is still better than the performance of the Lasso regression with 321 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction and Meaning Extraction Using LSA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction and Performance Using LSA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we use .toarray() when performing PCA, but not when applying LSA\n",
    "- Scikit-learn's PCA cannot directly handle sparse vector formats, meaning matrices generated by CountVectorizer or TfidfVectorizer cannot be used as is. Therefore, to convert a sparse matrix into a standard numpy array, you need to first use the toarray() method. \n",
    "- On the other hand, TruncatedSVD can process sparse vector formats directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Converted X shape: (2034, 2000)\n",
      "Sum of explained variance ratio: 1.000\n",
      "#Train set score: 0.962\n",
      "#Test set score: 0.761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=2000, random_state=7)  # Specify the number of components to compress\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)\n",
    "\n",
    "print('LSA Converted X shape:', X_train_lsa.shape)\n",
    "# Print the sum of the explained variance ratio to see how much variance is explained by the selected components\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "LR_clf.fit(X_train_lsa, y_train)  # Train the classifier on the LSA-transformed data\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_lsa, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_lsa, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Converted X shape: (2034, 100)\n",
      "Sum of explained variance ratio: 0.209\n",
      "#Train set score: 0.811\n",
      "#Test set score: 0.743\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=1)  # Specify the number of components to compress\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)\n",
    "\n",
    "print('LSA Converted X shape:', X_train_lsa.shape)\n",
    "# Print the sum of the explained variance ratio to see how much variance is explained by the selected components\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "LR_clf.fit(X_train_lsa, y_train)  # Train the classifier on the LSA-transformed data\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_lsa, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_lsa, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minjoo",
   "language": "python",
   "name": "iitpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
