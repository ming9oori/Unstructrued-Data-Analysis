{"cells":[{"cell_type":"markdown","metadata":{"id":"X3sm_hIGl4Uk"},"source":["# 1. Classic Methods\n","\n"]},{"cell_type":"markdown","source":["Contents\n","1. Bag of Words (BOW)\n","2. TF-IDF"],"metadata":{"id":"peUZ5FCXuAD_"}},{"cell_type":"markdown","metadata":{"id":"IrHlA4yvl4Up"},"source":["## Generating Count Vectors Based on BOW (Bag of Words)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hbm7VQ6cqdNv","executionInfo":{"status":"ok","timestamp":1728267216364,"user_tz":-540,"elapsed":22804,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"outputId":"e9c72190-3d82-4acf-f1b1-970c63f6cac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WV9Pujapl4Uq","executionInfo":{"status":"ok","timestamp":1728267317520,"user_tz":-540,"elapsed":4635,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f9fc7a0-ae34-448e-93ef-1f89d3f4342b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import nltk\n","nltk.download('movie_reviews')\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa28fosyl4Ut","executionInfo":{"status":"ok","timestamp":1728267326860,"user_tz":-540,"elapsed":344,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"92f05e90-0b3e-4810-b589-04910179d96c"},"outputs":[{"output_type":"stream","name":"stdout","text":["#review count: 2000\n","#samples of file ids: ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n","#categories of reviews: ['neg', 'pos']\n","#num of \"neg\" reviews: 1000\n","#num of \"pos\" reviews: 1000\n","#id of the first review: neg/cv000_29416.txt\n","#first review content:\n"," plot : two teen couples go to a church party , drink and then drive . \n","they get into an accident . \n","one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n","w\n","\n","#sentence tokenization result: [['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.']]\n","#word tokenization result: ['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n"]}],"source":["from nltk.corpus import movie_reviews\n","\n","print('#review count:', len(movie_reviews.fileids())) # Returns the IDs of movie review documents\n","print('#samples of file ids:', movie_reviews.fileids()[:10]) # Outputs the first 10 IDs\n","print('#categories of reviews:', movie_reviews.categories()) # Label, i.e., classification of reviews as positive or negative\n","print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) # Returns the IDs of documents labeled as negative\n","print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) # Returns the IDs of documents labeled as positive\n","fileid = movie_reviews.fileids()[0] # Returns the ID of the first document\n","print('#id of the first review:', fileid)\n","print('#first review content:\\n', movie_reviews.raw(fileid)[:200]) # Outputs the first 200 characters of the content from the first document\n","print()\n","print('#sentence tokenization result:', movie_reviews.sents(fileid)[:2]) # The first two sentences after sentence tokenization of the first document\n","print('#word tokenization result:', movie_reviews.words(fileid)[:20]) # The first 20 words after word tokenization of the first document"]},{"cell_type":"markdown","source":["In typical text mining processes, text representation is not implemented directly, but libraries such as Scikit-learn are used. However, this time, let's implement it manually to gain a precise understanding of Bag of Words (BOW)."],"metadata":{"id":"h-KEF8hQLCqi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnaUMSnNl4Uu","executionInfo":{"status":"ok","timestamp":1728267356947,"user_tz":-540,"elapsed":3846,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7181f7cb-0eb8-4d02-b3ae-0ccdd1811b14"},"outputs":[{"output_type":"stream","name":"stdout","text":["['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch']\n"]}],"source":["# This will create a list where each document is tokenized into words, resulting in a list of tokens for each document.\n","documents = [list(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()] # Using fileids(), retrieve the IDs of all documents, and for each ID, use words() to get the tokenized results and create a list.\n","print(documents[0][:50]) # Outputs the first 50 words of the first document"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9nCqnkKl4Uu","executionInfo":{"status":"ok","timestamp":1728267406074,"user_tz":-540,"elapsed":864,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff36cde1-8219-4a13-a6c2-027d8722f6cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["count of ',': 77717, count of 'the': 76529, count of '.': 65876, count of 'a': 38106, count of 'and': 35576, count of 'of': 34123, count of 'to': 31937, count of ''': 30585, count of 'is': 25195, count of 'in': 21822, "]}],"source":["# Initialize an empty dictionary to store word counts\n","word_count = {}\n","\n","# Iterate through each document (list of words) in the documents list\n","for text in documents:\n","    # Iterate through each word in the document\n","    for word in text:\n","        # Update the word count in the dictionary.\n","        # If the word is not in the dictionary, add it with a count of 1.\n","        # Otherwise, increment its count by 1.\n","        word_count[word] = word_count.get(word, 0) + 1\n","\n","# Sort the words in the word_count dictionary based on their frequency in descending order.\n","sorted_features = sorted(word_count, key=word_count.get, reverse=True)\n","\n","# Print the top 10 most frequent words and their counts\n","for word in sorted_features[:10]:\n","    # Print the word and its count, separated by commas\n","    print(f\"count of '{word}': {word_count[word]}\", end=', ')"]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"id":"WVHSJMJjodVx","executionInfo":{"status":"ok","timestamp":1728267415504,"user_tz":-540,"elapsed":385,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6760f785-5e4a-4d5f-d593-7e93e539fa4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ISdcv6jl4Uv","executionInfo":{"status":"ok","timestamp":1728267440762,"user_tz":-540,"elapsed":1276,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e0fcafe-e9fc-4901-904e-0f70b5e215a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["num of words/features: 43030\n","count of 'film': 8935, count of 'one': 5791, count of 'movie': 5538, count of 'like': 3690, count of 'even': 2564, count of 'time': 2409, count of 'good': 2407, count of 'story': 2136, count of 'would': 2084, count of 'much': 2049, "]}],"source":["from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords # Words generally not targeted for analysis\n","\n","tokenizer = RegexpTokenizer(\"[\\w']{3,}\") # Defines the tokenizer using a regular expression\n","english_stops = set(stopwords.words('english')) # Retrieves English stopwords\n","\n","# Uses raw() instead of words() to get the original text\n","documents = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n","\n","# Performs both tokenization and stopwords removal simultaneously\n","tokens = [[token for token in tokenizer.tokenize(doc) if token not in english_stops] for doc in documents]\n","\n","word_count = {}\n","for text in tokens:\n","    for word in text:\n","        word_count[word] = word_count.get(word, 0) + 1\n","\n","sorted_features = sorted(word_count, key=word_count.get, reverse=True)\n","\n","print('num of words/features:', len(sorted_features))\n","for word in sorted_features[:10]:\n","    print(f\"count of '{word}': {word_count[word]}\", end=', ')"]},{"cell_type":"markdown","source":["- You can use all of the features above, but we decided to extract only the top 1,000 most frequent ones to use as the final features representing the document.\n","- The important point here is that the feature set has an order, and this order determines the count vector values for the document."],"metadata":{"id":"xRiaep76NNep"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8X_05JZl4Uw"},"outputs":[],"source":["word_features = sorted_features[:1000] # Extracts the top 1000 most frequent words to construct features"]},{"cell_type":"markdown","source":["Now, we will create a function that converts the given document into a feature vector, i.e., a count vector. To verify that the function works properly, let's create input and output examples as shown below and test it."],"metadata":{"id":"vknrp40vNusK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKQ2IU8Ql4Uw","executionInfo":{"status":"ok","timestamp":1728267577376,"user_tz":-540,"elapsed":351,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"09260014-e1d3-4c73-a3bf-5cbb23342adf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 2, 0, 1, 0]\n"]}],"source":["def document_features(document, word_features):\n","    word_count = {}  # Initialize an empty dictionary to store word counts\n","    for word in document:  # First, calculates the frequency of words in the document\n","        word_count[word] = word_count.get(word, 0) + 1  # Update word count or set to 1 if the word is not yet in the dictionary\n","\n","    features = []  # Initialize an empty list to store the feature vector\n","    for word in word_features:  # Adds the calculated frequency of each word in word_features to the feature list\n","        features.append(word_count.get(word, 0))  # Insert 0 if the word is not in the document\n","    return features  # Return the feature vector\n","\n","word_features_ex = ['one', 'two', 'teen', 'couples', 'solo'] # This is a list of words that will be used as the feature vector. The frequency of these words in the document will be measured.\n","doc_ex = ['two', 'two', 'couples'] # This is the document you want to convert. It is a list of words. For example, this document contains the word 'two' twice and 'couples' once.\n","print(document_features(doc_ex, word_features_ex))#gives the number of appearances"]},{"cell_type":"markdown","source":["Since it has been confirmed to work well, let's now apply it to the entire review set, and print the number of extracted features and the first 20 features from the feature set of the first review document. At this time, to know which word corresponds to the value in the vector, we will output it along with the words from word_features in the matching order."],"metadata":{"id":"wnlwNHWyPoTq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpDvI8gXl4Ux","executionInfo":{"status":"ok","timestamp":1728267702899,"user_tz":-540,"elapsed":1241,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9f25b32-6ea0-4ed3-ee26-b25e8a4c8cb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["(film, 5), (one, 3), (movie, 6), (like, 3), (even, 3), (time, 0), (good, 2), (story, 0), (would, 1), (much, 0), (also, 1), (get, 3), (character, 1), (two, 2), (well, 1), (first, 0), (characters, 1), (see, 2), (way, 3), (make, 5), "]}],"source":["# Create a list of word frequency vectors for each document in 'tokens'\n","# 'word_features' is the list of words whose frequencies we want to check\n","feature_sets = [document_features(d, word_features) for d in tokens]\n","\n","# Print the first 20 word frequencies from the first document's feature vector\n","for i in range(20):\n","    # Print the word from 'word_features' and its frequency in the first document\n","    print(f'({word_features[i]}, {feature_sets[0][i]})', end=', ')"]},{"cell_type":"markdown","source":["- The words in word_features are sorted in order of frequency.\n","Therefore, we can see that many of the first 20 words have non-zero count values.\n","- However, as we move towards the end, we can predict that more words will have a count of 0. To confirm this, if we print the last 20 values as shown below, we can observe that they are all 0."],"metadata":{"id":"PxwCjMvKRbnu"}},{"cell_type":"code","source":["print(feature_sets[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rX-LJcGryBDR","executionInfo":{"status":"ok","timestamp":1728267706678,"user_tz":-540,"elapsed":347,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"outputId":"e15b8a48-2674-430d-eef2-c59ceee1f3a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 3, 6, 3, 3, 0, 2, 0, 1, 0, 1, 3, 1, 2, 1, 0, 1, 2, 3, 5, 1, 2, 2, 1, 2, 1, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["print(feature_sets[0][-20:]) # Print only the last 20 feature sets , limitations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sel72h0KQ88i","executionInfo":{"status":"ok","timestamp":1728267771817,"user_tz":-540,"elapsed":416,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"outputId":"15f28b82-67eb-42e4-dcc6-a98701f32a75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["print(feature_sets[0][:20]) # Print only the last 20 feature sets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3YZ93muRybH","executionInfo":{"status":"ok","timestamp":1728267774787,"user_tz":-540,"elapsed":478,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"outputId":"1c476ff4-97fa-4acb-cd83-c56f24a679ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 3, 6, 3, 3, 0, 2, 0, 1, 0, 1, 3, 1, 2, 1, 0, 1, 2, 3, 5]\n"]}]},{"cell_type":"markdown","metadata":{"id":"w3FKGvRTl4Uy"},"source":["## Generating Count Vectors Using Scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"pzmYotK1l4Uy"},"source":["### CountVectorizer\n","\n","http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction  "]},{"cell_type":"markdown","source":["- If you want to represent documents based on counts and analyze them using machine learning, it's much more convenient to use Scikit-learn's text-related libraries.\n","- Scikit-learn supports its own tokenizer, so users do not need to tokenize separately. However, if you want to improve performance with more fine-tuning, you can define the tokenizer as a function and use it within Scikit-learn.\n","- In the case of Korean, you must use a separate tokenizer because morphological analysis needs to be performed with KoNLPy."],"metadata":{"id":"ZZ29qqUaSGB-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0F58FFtl4Uz"},"outputs":[],"source":["# Data preparation, extracting raw text using movie_reviews.raw()\n","reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]"]},{"cell_type":"code","source":["reviews[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"f1t7vWsgS4I9","executionInfo":{"status":"ok","timestamp":1728267797420,"user_tz":-540,"elapsed":418,"user":{"displayName":"Aylin Fathi","userId":"06924576405563082867"}},"outputId":"3515a297-3fe1-4747-8afa-f1744dd18aee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn\\'t snag this one correctly . \\nthey seem to have taken this pretty neat concept , but executed it terribly . \\nso what are the problems with the movie ? \\nwell , its main problem is that it\\'s simply too jumbled . \\nit starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what\\'s going on . \\nthere are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \\nnow i personally don\\'t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film\\'s biggest problem . \\nit\\'s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \\nand do they make things entertaining , thrilling or even engaging , in the meantime ? \\nnot really . \\nthe sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn\\'t the make the film all that more entertaining . \\ni guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \\ni mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \\nokay , we get it . . . there \\nare people chasing her and we don\\'t know who they are . \\ndo we really need to see it over and over again ? \\nhow about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \\napparently , the studio took this film away from its director and chopped it up themselves , and it shows . \\nthere might\\'ve been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \\nthe actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \\nbut my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character\\'s unraveling . \\noverall , the film doesn\\'t stick because it doesn\\'t entertain , it\\'s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \\noh , and by the way , this is not a horror or teen slasher flick . . . it\\'s \\njust packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \\nit also wrapped production two years ago and has been sitting on the shelves ever since . \\nwhatever . . . skip \\nit ! \\nwhere\\'s joblo coming from ? \\na nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \\n',\n"," 'the happy bastard\\'s quick movie review \\ndamn that y2k bug . \\nit\\'s got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . \\nlittle do they know the power within . . . \\ngoing for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . \\nwe don\\'t know why the crew was really out in the middle of nowhere , we don\\'t know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don\\'t know why donald sutherland is stumbling around drunkenly throughout . \\nhere , it\\'s just \" hey , let\\'s chase these people around with some robots \" . \\nthe acting is below average , even from the likes of curtis . \\nyou\\'re more likely to get a kick out of her work in halloween h20 . \\nsutherland is wasted and baldwin , well , he\\'s acting like a baldwin , of course . \\nthe real star here are stan winston\\'s robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone\\'s brain . \\nso , if robots and body parts really turn you on , here\\'s your movie . \\notherwise , it\\'s pretty much a sunken ship of a movie . \\n',\n"," \"it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . \\nbased on the late 1960's television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . \\nhowever , things go wrong as evidence gets stolen and they are immediately under suspicion . \\nof course , the ads make it seem like so much more . \\nquick cuts , cool music , claire dane's nice hair and cute outfits , car chases , stuff blowing up , and the like . \\nsounds like a cool movie , does it not ? \\nafter the first fifteen minutes , it quickly becomes apparent that it is not . \\nthe mod squad is certainly a slick looking production , complete with nice hair and costumes , but that simply isn't enough . \\nthe film is best described as a cross between an hour-long cop show and a music video , both stretched out into the span of an hour and a half . \\nand with it comes every single clich ? . \\nit doesn't really matter that the film is based on a television show , as most of the plot elements have been recycled from everything we've already seen . \\nthe characters and acting is nothing spectacular , sometimes even bordering on wooden . \\nclaire danes and omar epps deliver their lines as if they are bored , which really transfers onto the audience . \\nthe only one to escape relatively unscathed is giovanni ribisi , who plays the resident crazy man , ultimately being the only thing worth watching . \\nunfortunately , even he's not enough to save this convoluted mess , as all the characters don't do much apart from occupying screen time . \\nwith the young cast , cool clothes , nice hair , and hip soundtrack , it appears that the film is geared towards the teenage mindset . \\ndespite an american 'r' rating ( which the content does not justify ) , the film is way too juvenile for the older mindset . \\ninformation on the characters is literally spoon-fed to the audience ( would it be that hard to show us instead of telling us ? ) , dialogue is poorly written , and the plot is extremely predictable . \\nthe way the film progresses , you likely won't even care if the heroes are in any jeopardy , because you'll know they aren't . \\nbasing the show on a 1960's television show that nobody remembers is of questionable wisdom , especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand ( even one that's missing a finger or two ) . \\nthe number of times that i checked my watch ( six ) is a clear indication that this film is not one of them . \\nit is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar , judging from the rash of really awful teen-flicks that we've been seeing as of late . \\navoid this film at all costs . \\n\",\n"," ' \" quest for camelot \" is warner bros . \\' first feature-length , fully-animated attempt to steal clout from disney\\'s cartoon empire , but the mouse has no reason to be worried . \\nthe only other recent challenger to their throne was last fall\\'s promising , if flawed , 20th century fox production \" anastasia , \" but disney\\'s \" hercules , \" with its lively cast and colorful palate , had her beat hands-down when it came time to crown 1997\\'s best piece of animation . \\nthis year , it\\'s no contest , as \" quest for camelot \" is pretty much dead on arrival . \\neven the magic kingdom at its most mediocre -- that\\'d be \" pocahontas \" for those of you keeping score -- isn\\'t nearly as dull as this . \\nthe story revolves around the adventures of free-spirited kayley ( voiced by jessalyn gilsig ) , the early-teen daughter of a belated knight from king arthur\\'s round table . \\nkayley\\'s only dream is to follow in her father\\'s footsteps , and she gets her chance when evil warlord ruber ( gary oldman ) , an ex-round table member-gone-bad , steals arthur\\'s magical sword excalibur and accidentally loses it in a dangerous , booby-trapped forest . \\nwith the help of hunky , blind timberland-dweller garrett ( carey elwes ) and a two-headed dragon ( eric idle and don rickles ) that\\'s always arguing with itself , kayley just might be able to break the medieval sexist mold and prove her worth as a fighter on arthur\\'s side . \\n \" quest for camelot \" is missing pure showmanship , an essential element if it\\'s ever expected to climb to the high ranks of disney . \\nthere\\'s nothing here that differentiates \" quest \" from something you\\'d see on any given saturday morning cartoon -- subpar animation , instantly forgettable songs , poorly-integrated computerized footage . \\n ( compare kayley and garrett\\'s run-in with the angry ogre to herc\\'s battle with the hydra . \\ni rest my case . ) \\neven the characters stink -- none of them are remotely interesting , so much that the film becomes a race to see which one can out-bland the others . \\nin the end , it\\'s a tie -- they all win . \\nthat dragon\\'s comedy shtick is awfully cloying , but at least it shows signs of a pulse . \\nat least fans of the early-\\'90s tgif television line-up will be thrilled to find jaleel \" urkel \" white and bronson \" balki \" pinchot sharing the same footage . \\na few scenes are nicely realized ( though i\\'m at a loss to recall enough to be specific ) , and the actors providing the voice talent are enthusiastic ( though most are paired up with singers who don\\'t sound a thing like them for their big musical moments -- jane seymour and celine dion ? ? ? ) . \\nbut one must strain through too much of this mess to find the good . \\naside from the fact that children will probably be as bored watching this as adults , \" quest for camelot \" \\'s most grievous error is its complete lack of personality . \\nand personality , we learn from this mess , goes a very long way . \\n',\n"," 'synopsis : a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal accident and then falls in love with the boy\\'s mother , a fledgling restauranteur . \\nunsuccessfully attempting to gain the woman\\'s favor , he takes pictures of her and kills a number of people in his way . \\ncomments : stalked is yet another in a seemingly endless string of spurned-psychos-getting-their-revenge type movies which are a stable category in the 1990s film industry , both theatrical and direct-to-video . \\ntheir proliferation may be due in part to the fact that they\\'re typically inexpensive to produce ( no special effects , no big name stars ) and serve as vehicles to flash nudity ( allowing them to frequent late-night cable television ) . \\nstalked wavers slightly from the norm in one respect : the psycho never actually has an affair ; on the contrary , he\\'s rejected rather quickly ( the psycho typically is an ex-lover , ex-wife , or ex-husband ) . \\nother than that , stalked is just another redundant entry doomed to collect dust on video shelves and viewed after midnight on cable . \\nstalked does not provide much suspense , though that is what it sets out to do . \\ninterspersed throughout the opening credits , for instance , a serious-sounding narrator spouts statistics about stalkers and ponders what may cause a man to stalk ( it\\'s implicitly implied that all stalkers are men ) while pictures of a boy are shown on the screen . \\nafter these credits , a snapshot of actor jay underwood appears . \\nthe narrator states that \" this is the story of daryl gleason \" and tells the audience that he is the stalker . \\nof course , really , this is the story of restauranteur brooke daniels . \\nif the movie was meant to be about daryl , then it should have been called stalker not stalked . \\nokay . so we know who the stalker is even before the movie starts ; no guesswork required . \\nstalked proceeds , then , as it begins : obvious , obvious , obvious . \\nthe opening sequence , contrived quite a bit , brings daryl and brooke ( the victim ) together . \\ndaryl obsesses over brooke , follows her around , and tries to woo her . \\nultimately rejected by her , his plans become more and more desperate and elaborate . \\nthese plans include the all-time , psycho-in-love , cliche : the murdered pet . \\nfor some reason , this genre\\'s films require a dead pet to be found by the victim stalked . \\nstalked is no exception ( it\\'s a cat this time -- found in the shower ) . \\nevents like these lead to the inevitable showdown between stalker and stalked , where only one survives ( guess who it invariably always is and you\\'ll guess the conclusion to this turkey ) . \\nstalked\\'s cast is uniformly adequate : not anything to write home about but also not all that bad either . \\njay underwood , as the stalker , turns toward melodrama a bit too much . \\nhe overdoes it , in other words , but he still manages to be creepy enough to pass as the type of stalker the story demands . \\nmaryam d\\'abo , about the only actor close to being a star here ( she played the bond chick in the living daylights ) , is equally adequate as the \" stalked \" of the title , even though she seems too ditzy at times to be a strong , independent business-owner . \\nbrooke ( d\\'abo ) needs to be ditzy , however , for the plot to proceed . \\ntoward the end , for example , brooke has her suspicions about daryl . \\nto ensure he won\\'t use it as another excuse to see her , brooke decides to return a toolbox he had left at her place to his house . \\ndoes she just leave the toolbox at the door when no one answers ? \\nof course not . \\nshe tries the door , opens it , and wanders around the house . \\nwhen daryl returns , he enters the house , of course , so our heroine is in danger . \\nsomehow , even though her car is parked at the front of the house , right by the front door , daryl is oblivious to her presence inside . \\nthe whole episode places an incredible strain on the audience\\'s suspension of disbelief and questions the validity of either character\\'s intelligence . \\nstalked receives two stars because , even though it is highly derivative and somewhat boring , it is not so bad that it cannot be watched . \\nrated r mostly for several murder scenes and brief nudity in a strip bar , it is not as offensive as many other thrillers in this genre are . \\nif you\\'re in the mood for a good suspense film , though , stake out something else . \\n']"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["When creating a CountVectorizer object, you can use the vocabulary parameter to construct vectors using only the words present in the previously created word_features."],"metadata":{"id":"gbgqVQoZTzby"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j81B2hzNl4Uz","executionInfo":{"status":"ok","timestamp":1728260766864,"user_tz":-540,"elapsed":15,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee76b50f-f63d-469a-c052-9e6fd6a9b161"},"outputs":[{"output_type":"stream","name":"stdout","text":["CountVectorizer(vocabulary=['film', 'one', 'movie', 'like', 'even', 'time',\n","                            'good', 'story', 'would', 'much', 'also', 'get',\n","                            'character', 'two', 'well', 'first', 'characters',\n","                            'see', 'way', 'make', 'life', 'really', 'films',\n","                            'plot', 'little', 'people', 'could', 'bad', 'scene',\n","                            'never', ...])\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# cv = CountVectorizer() # When using default values for all parameters\n","\n","# When specifying the feature set using the previously generated word_features\n","cv = CountVectorizer(vocabulary=word_features)\n","\n","# cv = CountVectorizer(max_features=1000) # When not specifying the feature set but setting the maximum number of features\n","print(cv) # Checks the arguments used in the object"]},{"cell_type":"markdown","source":["- Once the object is created, you can generate the feature set and create the count vector using fit_transform() as shown below.\n","- You can see that the output of get_feature_names_out() has the same words and order as word_features.\n"],"metadata":{"id":"Y1OyAhx3UNKM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hh3PM3Zll4Uz","executionInfo":{"status":"ok","timestamp":1728260768544,"user_tz":-540,"elapsed":1685,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17c3520d-29c1-4055-f413-714a7c90dce9"},"outputs":[{"output_type":"stream","name":"stdout","text":["['film' 'one' 'movie' 'like' 'even' 'time' 'good' 'story' 'would' 'much'\n"," 'also' 'get' 'character' 'two' 'well' 'first' 'characters' 'see' 'way'\n"," 'make']\n","['film', 'one', 'movie', 'like', 'even', 'time', 'good', 'story', 'would', 'much', 'also', 'get', 'character', 'two', 'well', 'first', 'characters', 'see', 'way', 'make']\n"]}],"source":["reviews_cv = cv.fit_transform(reviews) # Learn and transform using reviews for the count vector\n","print(cv.get_feature_names_out()[:20]) # Return the feature names used in the count vector\n","print(word_features[:20]) # Output for comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fT7eUICl4U0","executionInfo":{"status":"ok","timestamp":1728260768545,"user_tz":-540,"elapsed":26,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a6db577-832b-4a8d-e345-84dc23ae24a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["#type of count vectors: <class 'scipy.sparse._csr.csr_matrix'>\n","#shape of count vectors: (2000, 1000)\n","#sample of count vector:\n","  (0, 0)\t6\n","  (0, 1)\t3\n","  (0, 2)\t6\n","  (0, 3)\t3\n","  (0, 4)\t3\n","  (0, 6)\t2\n","  (0, 8)\t1\n"]}],"source":["print('#type of count vectors:', type(reviews_cv))\n","print('#shape of count vectors:', reviews_cv.shape)\n","print('#sample of count vector:')\n","print(reviews_cv[0, :10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecFupVj_l4U0","executionInfo":{"status":"ok","timestamp":1728260768545,"user_tz":-540,"elapsed":21,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3481afba-53f9-49bf-b3d0-1e535997793c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2000x1000 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 252984 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":64}],"source":["reviews_cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CPSCXLal4U0","executionInfo":{"status":"ok","timestamp":1728260768545,"user_tz":-540,"elapsed":18,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"62f05635-e6d1-4b8b-96f4-b361baf7eef6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 3, 6, 3, 3, 0, 2, 0, 1, 0, 1, 3, 1, 2, 1, 0, 1, 2, 3, 5]\n","[6 3 6 3 3 0 2 0 1 0 1 3 2 2 1 0 1 2 3 5]\n"]}],"source":["print(feature_sets[0][:20]) # Count vector manually calculated earlier\n","print(reviews_cv.toarray()[0, :20]) # Output the first 20 elements of the transformed result's first feature set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAsBy8tsl4U1","executionInfo":{"status":"ok","timestamp":1728260768545,"user_tz":-540,"elapsed":15,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"90e58cac-848f-4d1f-914b-78e90a7e6563"},"outputs":[{"output_type":"stream","name":"stdout","text":["film:6, one:3, movie:6, like:3, even:3, time:0, good:2, story:0, would:1, much:0, also:1, get:3, character:2, two:2, well:1, first:0, characters:1, see:2, way:3, make:5, "]}],"source":["for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n","    print(f'{word}:{count}', end=', ')"]},{"cell_type":"markdown","metadata":{"id":"J55IlrnPl4U1"},"source":["## Converting Korean Text into Count Vectors\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27TkF1n_l4U1","executionInfo":{"status":"ok","timestamp":1728260768545,"user_tz":-540,"elapsed":12,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"2d44ae82-c04b-4c61-f46f-c9a3fea68447"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              review  rating        date  \\\n","0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n","1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n","2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n","3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n","4                                               재미있다      10  2018.10.20   \n","5                                           나는 재밌게 봄      10  2018.10.14   \n","6                                      0.5점은 줄 수 없냐?       0  2018.10.10   \n","7                     헐..다 죽었어....나중에 앤트맨 보다가도 깜놀...      10  2018.10.08   \n","8                                              충격 결말       9  2018.10.06   \n","9                                                응집력       8  2018.10.05   \n","\n","    title  \n","0  인피니티 워  \n","1  인피니티 워  \n","2  인피니티 워  \n","3  인피니티 워  \n","4  인피니티 워  \n","5  인피니티 워  \n","6  인피니티 워  \n","7  인피니티 워  \n","8  인피니티 워  \n","9  인피니티 워  "],"text/html":["\n","  <div id=\"df-b6094877-f4d9-444b-9ae9-ed378c458cfe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>rating</th>\n","      <th>date</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n","      <td>1</td>\n","      <td>2018.10.29</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n","      <td>10</td>\n","      <td>2018.10.26</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n","      <td>8</td>\n","      <td>2018.10.24</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>이 정도면 볼만하다고 할 수 있음!</td>\n","      <td>8</td>\n","      <td>2018.10.22</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>재미있다</td>\n","      <td>10</td>\n","      <td>2018.10.20</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>나는 재밌게 봄</td>\n","      <td>10</td>\n","      <td>2018.10.14</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.5점은 줄 수 없냐?</td>\n","      <td>0</td>\n","      <td>2018.10.10</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>헐..다 죽었어....나중에 앤트맨 보다가도 깜놀...</td>\n","      <td>10</td>\n","      <td>2018.10.08</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>충격 결말</td>\n","      <td>9</td>\n","      <td>2018.10.06</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>응집력</td>\n","      <td>8</td>\n","      <td>2018.10.05</td>\n","      <td>인피니티 워</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6094877-f4d9-444b-9ae9-ed378c458cfe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b6094877-f4d9-444b-9ae9-ed378c458cfe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b6094877-f4d9-444b-9ae9-ed378c458cfe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dfcd0bfc-0ea8-4d34-8752-690e66e23c87\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfcd0bfc-0ea8-4d34-8752-690e66e23c87')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dfcd0bfc-0ea8-4d34-8752-690e66e23c87 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 14725,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14317,\n        \"samples\": [\n          \"\\uc774 \\uc601\\ud654\\ub294 \\uc0c1\\ucc98\\uac00 \\uc544\\ubb3c\\uc9c0\\uc54a\\uc740 \\uacfc\\uac70\\uc0ac\\uc774\\uae30\\ub3c4 \\ud558\\uc9c0\\ub9cc \\uc601\\ud654\\ub85c\\uc11c\\ub3c4 \\uba4b\\uc9c4 \\uc5f0\\uae30\\uac00 \\ub3cb\\ubcf4\\uc774\\ub294 \\uc791\\ud488\\uc785\\ub2c8\\ub2e4\",\n          \"\\uc548\\uc878\\uace0 \\ub05d\\uae4c\\uc9c0 \\ubcf8\\uc601\\ud654 ^^ \\uc774\\uac74 \\uc601\\ud654\\uad00\\uc5d0\\uc11c \\ubd10\\uc57c \\ubab0\\uc785\\ub428\",\n          \"\\uc5f0\\ud734\\uae30\\uac04 \\ub9ce\\uc774\\ub4e4\\ubcf4\\uae30\\uc5d0 \\ubd24\\uc9c0\\ub9cc \\ubb3c\\ud0c0\\uae30\\uc77c\\ubfd0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 640,\n        \"samples\": [\n          \"2016.10.19\",\n          \"2017.09.27\",\n          \"2017.07.22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\uc778\\ud53c\\ub2c8\\ud2f0 \\uc6cc\",\n          \"\\ub77c\\ub77c\\ub79c\\ub4dc\",\n          \"\\ud0dd\\uc2dc\\uc6b4\\uc804\\uc0ac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":67}],"source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/Unstructured Data Analysis - Code Practice/[Week 6] Text Representation/data/daum_movie_review.csv')\n","df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIsYcwpwl4U1","executionInfo":{"status":"ok","timestamp":1728260769522,"user_tz":-540,"elapsed":984,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cdfd2253-5aab-4296-9dc8-4c98b983f844"},"outputs":[{"output_type":"stream","name":"stdout","text":["['10점' '18' '1987' '1도' '1점' '1점도' '2시간' '2시간이' '2편' '5점' '6점' '7점' '8점'\n"," 'cg' 'cg가' 'cg는' 'cg도' 'cg만' 'good' 'of' 'ㅋㅋ' 'ㅋㅋㅋ' 'ㅋㅋㅋㅋ' 'ㅎㅎ' 'ㅎㅎㅎ'\n"," 'ㅜㅜ' 'ㅠㅠ' 'ㅠㅠㅠ' 'ㅡㅡ' '가는' '가는줄' '가면' '가서' '가슴' '가슴아픈' '가슴이' '가장' '가족'\n"," '가족과' '가족들과' '가족의' '가족이' '가지고' '간만에' '갈수록' '감독' '감독님' '감독은' '감독의' '감독이'\n"," '감동' '감동과' '감동도' '감동은' '감동을' '감동이' '감동입니다' '감동적' '감동적이고' '감동적인' '감사드립니다'\n"," '감사합니다' '감정이' '갑자기' '갔는데' '갔다가' '강철비' '강추' '강추합니다' '같고' '같네요' '같다' '같습니다'\n"," '같아' '같아요' '같은' '같은데' '같음' '같이' '개연성' '개연성이' '개인적으로' '거의' '겁나' '것도' '것은'\n"," '것을' '것이' '것이다' '겨울왕국' '결국' '결말' '결말이' '계속' '고맙습니다' '곤지암' '공포' '공포를'\n"," '공포영화' '관객']\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","daum_cv = CountVectorizer(max_features=1000)\n","\n","daum_DTM = daum_cv.fit_transform(df.review) # Learn and transform using reviews for the count vector\n","print(daum_cv.get_feature_names_out()[:100]) # Return the feature names used in the count vector"]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"id":"DyhAgsYwq-hB","executionInfo":{"status":"ok","timestamp":1728260773283,"user_tz":-540,"elapsed":3766,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c71ff028-26be-4803-961a-d2368da1dfd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhWX21CHl4U2","executionInfo":{"status":"ok","timestamp":1728260773283,"user_tz":-540,"elapsed":26,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4f24e74-104f-4a4e-b695-2a83370201dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["# Entire morphological analysis result: ['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n","# Extract only nouns: ['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n","# Part-of-speech tagging result: [('몰입', 'Noun'), ('할수밖에', 'Verb'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('어렵게', 'Adjective'), ('생각', 'Noun'), ('할', 'Verb'), ('필요없다', 'Adjective'), ('.', 'Punctuation'), ('내', 'Noun'), ('가', 'Josa'), ('전투', 'Noun'), ('에', 'Josa'), ('참여', 'Noun'), ('한', 'Determiner'), ('듯', 'Noun'), ('손', 'Noun'), ('에', 'Josa'), ('땀', 'Noun'), ('이남', 'Noun'), ('.', 'Punctuation')]\n"]}],"source":["from konlpy.tag import Okt # Import Twitter morphological analyzer from konlpy\n","twitter_tag = Okt()\n","\n","print('# Entire morphological analysis result:', twitter_tag.morphs(df.review[1]))\n","print('# Extract only nouns:', twitter_tag.nouns(df.review[1]))\n","print('# Part-of-speech tagging result:', twitter_tag.pos(df.review[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH_fMrljl4U2","executionInfo":{"status":"ok","timestamp":1728260773283,"user_tz":-540,"elapsed":11,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6eed34ac-df90-4ff8-f0e9-44c7228b19dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["My tokenizer result: ['몰입', '할수밖에', '없다', '어렵게', '생각', '할', '필요없다', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"]}],"source":["def my_tokenizer(doc):\n","    return [token for token, pos in twitter_tag.pos(doc) if pos in ['Noun', 'Verb', 'Adjective']]\n","\n","print(\"My tokenizer result:\", my_tokenizer(df.review[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc2lDXf1l4U2","executionInfo":{"status":"ok","timestamp":1728260833167,"user_tz":-540,"elapsed":59892,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6621f89d-1c83-43af-a1be-a86f26de8d66"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["['가' '가는' '가는줄' '가면' '가서' '가슴' '가장' '가족' '가족영화' '가지' '가치' '각색' '간' '간다'\n"," '간만' '갈' '갈수록' '감' '감독' '감동' '감사' '감사합니다' '감상' '감성' '감정' '감탄' '갑자기' '갔는데'\n"," '갔다' '갔다가' '강' '강철' '강추' '같고' '같네요' '같다' '같습니다' '같아' '같아요' '같은' '같은데'\n"," '같음' '개' '개그' '개봉' '개연' '개인' '거' '거기' '거리' '거의' '걱정' '건' '건가' '건지' '걸'\n"," '겁니다' '것' '게' '겨울왕국' '결론' '결말' '경찰' '경험' '계속' '고' '고맙습니다' '고민' '고생' '곤지암'\n"," '곳' '공감' '공포' '공포영화' '과' '과거' '관' '관객' '관객수' '관람' '광주' '괜찮은' '교훈' '구성'\n"," '국내' '국민' '군인' '군함도' '굿' '권선' '귀신' '그' '그것' '그게' '그날' '그냥' '그닥' '그대로'\n"," '그때' '그래픽']\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Specify the tokenizer and the maximum number of features\n","daum_cv = CountVectorizer(max_features=1000, tokenizer=my_tokenizer)\n","# If you only want to extract nouns, you can directly specify 'twitter_tag.nouns' in the tokenizer\n","\n","daum_DTM = daum_cv.fit_transform(df.review) # Learn and transform using reviews for the count vector\n","print(daum_cv.get_feature_names_out()[:100]) # Return the feature names used in the count vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BRi-Wrhl4U2","executionInfo":{"status":"ok","timestamp":1728260833167,"user_tz":-540,"elapsed":19,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b32a2dcf-8a9f-4976-e112-233747f492f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["<14725x1000 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 110800 stored elements in Compressed Sparse Row format>\n","0.007524617996604414\n"]}],"source":["print(repr(daum_DTM))\n","print(110800/(14725*1000))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tW9GWEal4U3","executionInfo":{"status":"ok","timestamp":1728260833168,"user_tz":-540,"elapsed":15,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a60ec0e5-116b-46ef-9afa-eee0a6f255c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["내 : 1, 듯 : 1, 몰입 : 1, 생각 : 1, 손 : 1, 없다 : 1, 할 : 1, "]}],"source":["for word, count in zip(daum_cv.get_feature_names_out(), daum_DTM[1].toarray()[0]):\n","    if count > 0:\n","        print(word, ':', count, end=', ')"]},{"cell_type":"markdown","metadata":{"id":"QTwVz0Jol4U4"},"source":["## Improve performance with TF-IDF"]},{"cell_type":"markdown","source":["- In a count vector, frequency acts as a kind of weight. In other words, in a count vector, the higher the frequency, the more the word tends to be treated as important. However, there is one problem we haven't considered yet. If a word appears in every document, is it really an important word? (e.g., a, an, the...)\n","\n","- In other words, words that appear in every document are not particularly important. To put it differently, the more documents a word appears in, the less important it becomes. This concept is reflected in the count vector through TF-IDF (Term Frequency-Inverse Document Frequency)."],"metadata":{"id":"a2aC43RbWO1o"}},{"cell_type":"markdown","source":["- To reuse the count matrix created earlier, use the TfidfTransformer.\n","- This helps save time."],"metadata":{"id":"cxb6VUx1XAy1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iB4tmubzl4U5","executionInfo":{"status":"ok","timestamp":1728260833168,"user_tz":-540,"elapsed":12,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c48cde3-b9a4-4656-8c6e-50f85c7bd5fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["# Shape of TF-IDF matrix: (2000, 1000)\n","# 20 count scores of the first review: [6 3 6 3 3 0 2 0 1 0 1 3 2 2 1 0 1 2 3 5]\n","# 20 TF-IDF scores of the first review: [0.13556199 0.06700076 0.14998642 0.0772298  0.08608998 0.\n"," 0.0609124  0.         0.03126552 0.         0.03242315 0.09567082\n"," 0.06575035 0.06518293 0.03225625 0.         0.0345017  0.06863314\n"," 0.10042383 0.16727495]\n"]}],"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","transformer = TfidfTransformer()\n","transformer\n","\n","reviews_tfidf = transformer.fit_transform(reviews_cv)\n","print('# Shape of TF-IDF matrix:', reviews_tfidf.shape) # Check that the shape of the TF-IDF matrix matches the count matrix\n","\n","# Output the first 20 values of the count vector for the first review\n","print('# 20 count scores of the first review:', reviews_cv[0].toarray()[0][:20])\n","# Output the first 20 values of the TF-IDF vector for the first review\n","print('# 20 TF-IDF scores of the first review:', reviews_tfidf[0].toarray()[0][:20])"]},{"cell_type":"markdown","source":["* If you want to create a TF-IDF matrix from the beginning, you can use TfidfVectorizer"],"metadata":{"id":"GyHY73y2XSic"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2P8zBdhql4U5"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","tf = TfidfVectorizer(vocabulary=word_features)\n","reviews_tf = tf.fit_transform(reviews)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2VabCx-l4U6","executionInfo":{"status":"ok","timestamp":1728260834448,"user_tz":-540,"elapsed":14,"user":{"displayName":"­손민주 | 인공지능학과 | 한양대(서울)","userId":"12088855146953780462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0136fa7e-4457-4187-9930-38c26206d1ae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2000x1000 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 252984 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":77}],"source":["reviews_tf"]},{"cell_type":"code","source":[],"metadata":{"id":"-lYpdtRcWJO9"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}